{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b36f25",
   "metadata": {},
   "source": [
    "# Bite 266. Composition, Inheritance, Abstract Base Class, what?\n",
    "\n",
    "   It’s not as bad as that sounds, really. If you don’t know the difference between composition and inheritance, I would recommend reading up on it from Real Python. As most of their articles, the subject is covered pretty thoroughly!\n",
    "The scenario:\n",
    "\n",
    "   So you’ve been tasked with scraping some presidential polling sites. The plan is to create a scraper that can be used on multiple sites.\n",
    "\n",
    "   I’ve already created the following namedtuples, but you will need to add type hints to them:\n",
    "\n",
    "   `Candidate`, `LeaderBoard`, and `Poll`\n",
    "\n",
    "   I’ve never tried to add type hinting to namedtuples, so it was a great learning experience for me and I hope to pass that experience along to you.\n",
    "\n",
    "   The plan is to create the following core classes:\n",
    "\n",
    "- File:\\\n",
    "    Variables:\n",
    "        name: str\n",
    "        path: Path\n",
    "    Methods:\n",
    "        data -> Optional[str]\n",
    "- Web:\\\n",
    "    Variables:\n",
    "        url: str\n",
    "        file: File\n",
    "    Methods:\n",
    "        data -> Optional[str]\n",
    "        soup -> Soup\n",
    "- Site(ABC):\\\n",
    "    Variables:\n",
    "        web: Web\n",
    "    Methods:\n",
    "        find_table -> str\n",
    "        parse_rows -> Union[List[LeaderBoard], List[Poll]]\n",
    "        polls -> Union[List[LeaderBoard], List[Poll]]\n",
    "        stats\n",
    "\n",
    "Site is an abstract base class which decorates some methods with abstractmethods!\n",
    "\n",
    "If you are not familiar with Abstract Base Classes, read up on the documentation: `ABC`\n",
    "\n",
    "__Adding new parsers__\n",
    "\n",
    "   After creating the core of the application, you will have to create parsers for The New York Times and RealClearPolitics. Don’t be scared by all the data, we’re only interested in the Current State of the Race table from NYTimes and the third table from RCP. Since the tables in RCP all pretty much have the same layout, your parser should work with any of them, but that won’t be checked.\n",
    "\n",
    "   The parsers should derive from the Site class. While coding this, I was able to get the `find_table` method to work for all sites, so that one is not decorated with `@abstractmethod`. The other methods however, need to be overwritten in order for them to be instantiated.\n",
    "\n",
    "- RealClearPolitics(Site):\\\n",
    "    Variables:\n",
    "        - web: Web\n",
    "    Methods:\n",
    "        - find_table -> str\n",
    "        - parse_rows -> List[Poll]\n",
    "        - polls -> List[Poll]\n",
    "        - stats\n",
    "- NYTimes(Site):\\\n",
    "    Variables:\n",
    "        - web: Web\n",
    "    Methods:\n",
    "        - find_table -> str\n",
    "        - parse_rows -> List[Poll]\n",
    "        - polls -> List[Poll]\n",
    "        - stats\n",
    "\n",
    "__The output format__\n",
    "\n",
    "   Each of the two different parsers will have different outputs. We’ll just keep it simple, but there are some rules to adhere to. First, this is what sample output from each should look like.\n",
    "\n",
    "   __NYTimes__\n",
    "\n",
    "```\n",
    "NYTimes\n",
    "=================================\n",
    "\n",
    "                   Pete Buttigieg\n",
    "---------------------------------\n",
    "National Polling Average: 10%\n",
    "       Pledged Delegates: 25\n",
    "Individual Contributions: $76.2m\n",
    "    Weekly News Coverage: 3\n",
    "\n",
    "                   Bernie Sanders\n",
    "---------------------------------\n",
    "    etc..\n",
    "        Weekly News Coverage: 3\n",
    "```\n",
    "\n",
    "__Things to note about this output:__\n",
    "\n",
    "- Starts and ends with blank lines\n",
    "- There is a similar output for each of the remaining candidates:\n",
    "    - Bernie Sanders\n",
    "    - Joseph R. Biden Jr.\n",
    "    - Tulsi Gabbard\n",
    "- Not shown here, but there is a blank line between each candidate\n",
    "- There are 33 equal (=) signs and hyphens (-) in the dividers\n",
    "- The name of the candidate is right aligned\n",
    "- The data lines are all right aligned\n",
    "- The values from the data lines are all left aligned\n",
    "\n",
    "etc.. is just a place holder, indicating that not all data was shown\n",
    "\n",
    "__RealClearPolitics__\n",
    "\n",
    "```\n",
    "RealClearPolitics\n",
    "=================\n",
    "    Biden: 214.0\n",
    "  Sanders: 142.0\n",
    "  Gabbard: 6.0\n",
    "```\n",
    "\n",
    "__Some things to note here.__\n",
    "\n",
    "- Starts and ends with blank line\n",
    "- This is the whole output for this scraper\n",
    "- There are as many equal (=) signs as the length of the title\n",
    "- The candidate last names are right aligned\n",
    "\n",
    "\n",
    "__Time to start coding__\n",
    "\n",
    "That's it. I've scattered a generous amount of docstring all over the code to try and make it as explicit as possible in order to help you out. When you complete this bite, you will have learned and or gained more experience with:\n",
    "\n",
    "- Object Oriented Programming\n",
    "- Dataclasses\n",
    "- Inheritance\n",
    "- Composition\n",
    "- Abstract Base Classes\n",
    "    - The @abstractmethod decorator\n",
    "- Type hinting namedtuples\n",
    "- String formatting\n",
    "- Web scraping with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d1de6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from collections import namedtuple\n",
    "from dataclasses import dataclass\n",
    "from datetime import date\n",
    "from os import getenv\n",
    "from pathlib import Path\n",
    "from typing import Any, List, Optional\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from bs4 import BeautifulSoup as Soup  # type: ignore\n",
    "\n",
    "TMP = getenv(\"TMP\", \"/tmp\")\n",
    "TODAY = date.today()\n",
    "Candidate = namedtuple(\"Candidate\", \"name votes\")\n",
    "LeaderBoard = namedtuple(\n",
    "    \"LeaderBoard\", \"Candidate Average Delegates Contributions Coverage\"\n",
    ")\n",
    "Poll = namedtuple(\n",
    "    \"Poll\",\n",
    "    \"Poll Date Sample Sanders Biden Gabbard Spread\",\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class File:\n",
    "    \"\"\"File represents a filesystem path.\n",
    "\n",
    "    Variables:\n",
    "        name: str -- The filename that will be created on the filesystem.\n",
    "        path: Path -- Path object created from the name passed in.\n",
    "\n",
    "    Methods:\n",
    "        [property]\n",
    "        data: -> Optional[str] -- If the file exists, it returns its contents.\n",
    "            If it does not exist, it returns None.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    path: Path = Path(TMP)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        name_with_date = str(TODAY) + '_' + self.name\n",
    "        self.path = self.path / name_with_date\n",
    "    \n",
    "    @property\n",
    "    def data(self) -> Optional[str]:\n",
    "        \n",
    "        if self.path.exists():\n",
    "            with open(self.path, 'r') as file:\n",
    "                content = file.read()\n",
    "            return content\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "@dataclass\n",
    "class Web:\n",
    "    \"\"\"Web object.\n",
    "\n",
    "    Web is an object that downloads the page from the url that is passed\n",
    "    to it and stores it in the File instance that is passed to it. If the\n",
    "    File already exists, it just reads the file, otherwise it downloads it\n",
    "    and stores it in File.\n",
    "\n",
    "    Variables:\n",
    "        url: str -- The url of the web page.\n",
    "        file: File -- The File object to store the page data into.\n",
    "\n",
    "    Methods:\n",
    "        [property]\n",
    "        data: -> Optional[str] -- Reads the text from File or retrieves it from the\n",
    "            web if it does not exists.\n",
    "\n",
    "        [property]\n",
    "        soup: -> Soup -- Parses the data from File and turns it into a BeautifulSoup\n",
    "            object.\n",
    "    \"\"\"\n",
    "    url: str\n",
    "    file: File\n",
    "        \n",
    "    @property\n",
    "    def data(self) -> Optional[str]:\n",
    "        \"\"\"Reads the data from the File object.\n",
    "\n",
    "        First it checks if the File object has any data. If it doesn't, it retrieves\n",
    "        it and saves it to the File. It then reads it from the File and returns it.\n",
    "\n",
    "        Returns:\n",
    "            Optional[str] -- The string data from the File object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def soup(self) -> Soup:\n",
    "        \"\"\"Converts string data from File into a BeautifulSoup object.\n",
    "\n",
    "        Returns:\n",
    "            Soup -- BeautifulSoup object created from the File.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7726e9e",
   "metadata": {},
   "source": [
    "Working with type hints in python:\n",
    "\n",
    "- __Optional__ is used when you want to define a specific type or None.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c155410",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = File('teste.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6f48b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/b5bd/AppData/Local/Temp/2022-04-19_teste.html')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b348798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25744c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a620a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66591e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6b139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33445e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Web:\n",
    "    \"\"\"Web object.\n",
    "\n",
    "    Web is an object that downloads the page from the url that is passed\n",
    "    to it and stores it in the File instance that is passed to it. If the\n",
    "    File already exists, it just reads the file, otherwise it downloads it\n",
    "    and stores it in File.\n",
    "\n",
    "    Variables:\n",
    "        url: str -- The url of the web page.\n",
    "        file: File -- The File object to store the page data into.\n",
    "\n",
    "    Methods:\n",
    "        [property]\n",
    "        data: -> Optional[str] -- Reads the text from File or retrieves it from the\n",
    "            web if it does not exists.\n",
    "\n",
    "        [property]\n",
    "        soup: -> Soup -- Parses the data from File and turns it into a BeautifulSoup\n",
    "            object.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "    @property\n",
    "    def data(self) -> Optional[str]:\n",
    "        \"\"\"Reads the data from the File object.\n",
    "\n",
    "        First it checks if the File object has any data. If it doesn't, it retrieves\n",
    "        it and saves it to the File. It then reads it from the File and returns it.\n",
    "\n",
    "        Returns:\n",
    "            Optional[str] -- The string data from the File object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def soup(self) -> Soup:\n",
    "        \"\"\"Converts string data from File into a BeautifulSoup object.\n",
    "\n",
    "        Returns:\n",
    "            Soup -- BeautifulSoup object created from the File.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class Site(ABC):\n",
    "    \"\"\"Site Abstract Base Class.\n",
    "\n",
    "    Defines the structure for the objects based on this class and defines the interfaces\n",
    "    that should be implemented in order to work properly.\n",
    "\n",
    "    Variables:\n",
    "        web: Web -- The web object stores the information needed to process\n",
    "            the data.\n",
    "\n",
    "    Methods:\n",
    "        find_table: -> str -- Parses the Web object for table elements and\n",
    "            returns the first one that it finds unless an integer representing\n",
    "            the required table is passed.\n",
    "\n",
    "        [abstractmethod]\n",
    "        parse_rows: -> Union[List[LeaderBoard], List[Poll]] -- Parses a BeautifulSoup\n",
    "            table element and returns the text found in the td elements as\n",
    "            namedtuples.\n",
    "\n",
    "        [abstractmethod]\n",
    "        polls: -> Union[List[LeaderBoard], List[Poll]] -- Does the parsing of the table\n",
    "            and rows for you. It takes the table index number if given, otherwise\n",
    "            parses table 0.\n",
    "\n",
    "        [abstractmethod]\n",
    "        stats: -- Formats the results from polls into a more user friendly\n",
    "            representation.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "    def find_table(self, loc: int = 0) -> str:\n",
    "        \"\"\"Finds the table elements from the Soup object\n",
    "\n",
    "        Keyword Arguments:\n",
    "            loc {int} -- Parses the Web object for table elements and\n",
    "                returns the first one that it finds unless an integer representing\n",
    "                the required table is passed. (default: {0})\n",
    "\n",
    "        Returns:\n",
    "            str -- The html table\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def parse_rows(self, table: Soup) -> List[Any]:\n",
    "        \"\"\"Abstract Method\n",
    "        \n",
    "        Parses the row data from the html table.\n",
    "\n",
    "        Arguments:\n",
    "            table {Soup} -- Parses a BeautifulSoup table element and\n",
    "                returns the text found in the td elements as NamedTuple.\n",
    "\n",
    "        Returns:\n",
    "            List[NamedTuple] -- List of NamedTuple that were created from the\n",
    "                table data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def polls(self, table: int = 0) -> List[Any]:\n",
    "        \"\"\"Abstract Method\n",
    "\n",
    "        Parses the data\n",
    "\n",
    "        The find_table and parse_rows methods are called for you and the table index\n",
    "        that is passed to it is used to get the correct table from the soup object.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            table {int} -- Does the parsing of the table and rows for you.\n",
    "                It takes the table index number if given, otherwise parses table 0.\n",
    "                (default: {0})\n",
    "\n",
    "        Returns:\n",
    "            List[NamedTuple] -- List of NamedTuple that were created from the\n",
    "                table data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def stats(self, loc: int = 0):\n",
    "        \"\"\"Abstract Method\n",
    "        \n",
    "        Produces the stats from the polls.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            loc {int} -- Formats the results from polls into a more user friendly\n",
    "            representation.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RealClearPolitics(Site):\n",
    "    \"\"\"RealClearPolitics object.\n",
    "\n",
    "    RealClearPolitics is a custom class to parse a Web instance from the\n",
    "    realclearpolitics website.\n",
    "\n",
    "    Variables:\n",
    "        web: Web -- The web object stores the information needed to process\n",
    "            the data.\n",
    "\n",
    "    Methods:\n",
    "        find_table: -> str -- Parses the Web object for table elements and\n",
    "            returns the first one that it finds unless an integer representing\n",
    "            the required table is passed.\n",
    "\n",
    "        parse_rows: -> List[Poll] -- Parses a BeautifulSoup table element and\n",
    "            returns the text found in the td elements as Poll namedtuples.\n",
    "\n",
    "        polls: -> List[Poll] -- Does the parsing of the table and rows for you.\n",
    "            It takes the table index number if given, otherwise parses table 0.\n",
    "\n",
    "        stats: -- Formats the results from polls into a more user friendly\n",
    "            representation:\n",
    "\n",
    "            Example:\n",
    "\n",
    "            RealClearPolitics\n",
    "            =================\n",
    "                Biden: 214.0\n",
    "              Sanders: 142.0\n",
    "              Gabbard: 6.0\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "    def parse_rows(self, table: Soup) -> List[Poll]:\n",
    "        \"\"\"Parses the row data from the html table.\n",
    "\n",
    "        Arguments:\n",
    "            table {Soup} -- Parses a BeautifulSoup table element and\n",
    "                returns the text found in the td elements as Poll namedtuples.\n",
    "\n",
    "        Returns:\n",
    "            List[Poll] -- List of Poll namedtuples that were created from the\n",
    "                table data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def polls(self, table: int = 0) -> List[Poll]:\n",
    "        \"\"\"Parses the data\n",
    "\n",
    "        The find_table and parse_rows methods are called for you and the table index\n",
    "        that is passed to it is used to get the correct table from the soup object.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            table {int} -- Does the parsing of the table and rows for you.\n",
    "                It takes the table index number if given, otherwise parses table 0.\n",
    "                (default: {0})\n",
    "\n",
    "        Returns:\n",
    "            List[Poll] -- List of Poll namedtuples that were created from the\n",
    "                table data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def stats(self, loc: int = 0):\n",
    "        \"\"\"Produces the stats from the polls.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            loc {int} -- Formats the results from polls into a more user friendly\n",
    "            representation.\n",
    "\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NYTimes(Site):\n",
    "    \"\"\"NYTimes object.\n",
    "\n",
    "    NYTimes is a custom class to parse a Web instance from the nytimes website.\n",
    "\n",
    "    Variables:\n",
    "        web: Web -- The web object stores the information needed to process\n",
    "            the data.\n",
    "\n",
    "    Methods:\n",
    "        find_table: -> str -- Parses the Web object for table elements and\n",
    "            returns the first one that it finds unless an integer representing\n",
    "            the required table is passed.\n",
    "\n",
    "        parse_rows: -> List[LeaderBoard] -- Parses a BeautifulSoup table element and\n",
    "            returns the text found in the td elements as LeaderBoard namedtuples.\n",
    "\n",
    "        polls: -> List[LeaderBoard] -- Does the parsing of the table and rows for you.\n",
    "            It takes the table index number if given, otherwise parses table 0.\n",
    "\n",
    "        stats: -- Formats the results from polls into a more user friendly\n",
    "            representation:\n",
    "\n",
    "            Example:\n",
    "\n",
    "            NYTimes\n",
    "            =================================\n",
    "\n",
    "                               Pete Buttigieg\n",
    "            ---------------------------------\n",
    "            National Polling Average: 10%\n",
    "                   Pledged Delegates: 25\n",
    "            Individual Contributions: $76.2m\n",
    "                Weekly News Coverage: 3\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    web: Web\n",
    "\n",
    "    def parse_rows(self, table: Soup) -> List[LeaderBoard]:\n",
    "        \"\"\"Parses the row data from the html table.\n",
    "\n",
    "        Arguments:\n",
    "            table {Soup} -- Parses a BeautifulSoup table element and\n",
    "                returns the text found in the td elements as LeaderBoard namedtuples.\n",
    "\n",
    "        Returns:\n",
    "            List[LeaderBoard] -- List of LeaderBoard namedtuples that were created from\n",
    "            the table data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def polls(self, table: int = 0) -> List[LeaderBoard]:\n",
    "        \"\"\"Parses the data\n",
    "\n",
    "        The find_table and parse_rows methods are called for you and the table index\n",
    "        that is passed to it is used to get the correct table from the soup object.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            table {int} -- Does the parsing of the table and rows for you.\n",
    "                It takes the table index number if given, otherwise parses table 0.\n",
    "                (default: {0})\n",
    "\n",
    "        Returns:\n",
    "            List[LeaderBoard] -- List of LeaderBoard namedtuples that were created from\n",
    "                the table data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def stats(self, loc: int = 0):\n",
    "        \"\"\"Produces the stats from the polls.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            loc {int} -- Formats the results from polls into a more user friendly\n",
    "            representation.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "def gather_data():\n",
    "    rcp_file = File(\"realclearpolitics.html\")\n",
    "    rcp_url = (\n",
    "        \"https://bites-data.s3.us-east-2.amazonaws.com/2020-03-10_realclearpolitics.html\"\n",
    "    )\n",
    "    rcp_web = Web(rcp_url, rcp_file)\n",
    "    rcp = RealClearPolitics(rcp_web)\n",
    "    rcp.stats(3)\n",
    "\n",
    "    nyt_file = File(\"nytimes.html\")\n",
    "    nyt_url = (\n",
    "        \"https://bites-data.s3.us-east-2.amazonaws.com/2020-03-10_nytimes.html\"\n",
    "    )\n",
    "    nyt_web = Web(nyt_url, nyt_file)\n",
    "    nyt = NYTimes(nyt_web)\n",
    "    nyt.stats()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gather_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
